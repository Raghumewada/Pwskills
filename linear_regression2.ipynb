{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725ac1b6-35fc-452b-9e83-8ea242d80e98",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it\n",
    "represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c5b80-738d-4e24-a925-7c2ffd56e1a1",
   "metadata": {},
   "source": [
    "R-squared (R¬≤) is a statistical measure in a linear regression model that represents the proportion of the variance in the dependent variable that is predictable from the independent variables. It is calculated as:\n",
    "\n",
    "R^2 = 1 - SSres/SStotal\n",
    "\n",
    "where \n",
    "1. ùëÜùëÜres is the sum of squares of the residuals, and \n",
    "2. SStot is the total sum of squares. \n",
    "3. R^2 ranges from 0 to 1, with 1 indicating perfect prediction."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d4913c9-1628-49c9-adea-c49c0d932278",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e508c5a-af76-4841-9d0b-3c7c2925201d",
   "metadata": {},
   "source": [
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87973cb4-19c7-4194-b2f8-de08af1ec94c",
   "metadata": {},
   "source": [
    "Adjusted R-squared adjusts the R-squared value for the number of predictors in the model, providing a more accurate measure when comparing models with different numbers of predictors. It is calculated as:\n",
    "\n",
    "Adjusted¬†R^2=1‚àí(((1‚àíR^2)/(n‚àík‚àí1))*(n-1))\n",
    "\n",
    "where\n",
    "\n",
    " - n is the number of observations and k is the number of predictors. Adjusted R ^2 can decrease if unnecessary predictors are added to the model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "423afbc1-12ce-4088-bac4-cbf0f4ce64b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01ca5478-b490-4a47-b39c-21c73c2f7468",
   "metadata": {},
   "source": [
    "Q3. When is it more appropriate to use adjusted R-squared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1a4d37-c6f6-41a5-8186-935002188f6b",
   "metadata": {},
   "source": [
    "Adjusted R-squared is more appropriate when comparing the goodness-of-fit of regression models with different numbers of predictors, as it accounts for the number of predictors and avoids overestimating the model's explanatory power."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d775125-ae40-40a5-a4ec-b186d1d54316",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ebd83bf-c1ab-4caf-ab06-e4778ceba3a8",
   "metadata": {},
   "source": [
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics\n",
    "calculated, and what do they represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb6503-af3b-4ce3-8427-392659acc644",
   "metadata": {},
   "source": [
    " - Root Mean Squared Error (RMSE): Measures the average magnitude of the errors between predicted and actual values. Calculated as:\n",
    "\n",
    " - Mean Squared Error (MSE): Measures the average of the squares of the errors. Calculated as:\n",
    " \n",
    "\n",
    " - Mean Absolute Error (MAE): Measures the average absolute difference between predicted and actual values. Calculated as:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "907fa0aa-e9c4-43d3-9ba3-f7529c524c35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469bf22b-b1f6-45b1-9785-998d89d45cc8",
   "metadata": {},
   "source": [
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in\n",
    "regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517644f1-c675-4dd3-bd39-b1af2c2b1177",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "\n",
    "- RMSE: Sensitive to large errors, providing a good measure when large errors are particularly undesirable.\n",
    " - MSE: Emphasizes larger errors due to squaring, useful for theoretical analysis and algorithm optimization.\n",
    " - MAE: Simple to interpret, less sensitive to outliers compared to RMSE and MSE.\n",
    " \n",
    "Disadvantages:\n",
    "\n",
    " - RMSE and MSE: Can be disproportionately affected by outliers due to squaring of errors.\n",
    " - MAE: Doesn't highlight large errors as effectively as RMSE and MSE."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ee03636-7094-4486-bea2-dc1ae22d8669",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4167b1dd-7368-435d-8d4e-59348195837f",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is\n",
    "it more appropriate to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a43925f-2996-4439-9183-fc31c3739f6f",
   "metadata": {},
   "source": [
    "Lasso regularization (Least Absolute Shrinkage and Selection Operator) adds a penalty equal to the absolute value of the magnitude of coefficients to the loss function, encouraging sparsity in the model (some coefficients can become zero). The loss function is:\n",
    "\n",
    "Ridge regularization adds a penalty equal to the square of the magnitude of coefficients, which shrinks coefficients but doesn't set any to zero:\n",
    "\n",
    "Use Lasso when feature selection is desired. Use Ridge when multicollinearity is a concern and all predictors should be retained."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c4f8284-e780-42a0-9b21-1d69bfcbc697",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39d7b8f2-b2fd-44c9-85f7-c68468cc7653",
   "metadata": {},
   "source": [
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an\n",
    "example to illustrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bb2a34-3d9d-4246-958f-68555456bb15",
   "metadata": {},
   "source": [
    "Regularized linear models add a penalty to the loss function for large coefficients, thus preventing the model from fitting the noise in the data. For example, in a dataset with 100 features but only 10 truly relevant, Lasso regularization can shrink the irrelevant coefficients to zero, simplifying the model and reducing overfitting."
   ]
  },
  {
   "cell_type": "raw",
   "id": "28ae31ed-d70b-4473-a98c-017e9a8ab563",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6342879-b0a8-4d1b-9a99-7a34cafaf95a",
   "metadata": {},
   "source": [
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best\n",
    "choice for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80e72e-2dc9-4c94-93bf-86bf3b0e175f",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "\n",
    " - Regularization can introduce bias, especially if the penalty term is too large.\n",
    " - Lasso can arbitrarily select one of the highly correlated variables, which may not be desirable.\n",
    " - Ridge retains all variables, which may not be ideal for very high-dimensional datasets.\n",
    " \n",
    "Regularized models may not perform well if the true underlying model has complex non-linear relationships or interactions not captured by linear models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce32548d-6073-4e53-8095-936d65c15879",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a865f112-0896-47f7-a416-6aba0185f0e7",
   "metadata": {},
   "source": [
    "Q9. You are comparing the performance of two regression models using different evaluation metrics.\n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better\n",
    "performer, and why? Are there any limitations to your choice of metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7cacf-d71f-44c6-b9f6-c566f71f437f",
   "metadata": {},
   "source": [
    "Choosing the better model depends on the specific context:\n",
    "\n",
    "Model A (RMSE = 10): Might be preferred if larger errors are particularly undesirable.\n",
    "Model B (MAE = 8): Provides a lower average error.\n",
    "Limitations: RMSE is more sensitive to outliers than MAE. If the dataset has outliers, RMSE might give a misleadingly high impression of error severity."
   ]
  },
  {
   "cell_type": "raw",
   "id": "df953ff8-e059-4216-842a-6f8b73a5e817",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34889141-85d3-4d8b-8cf3-1edf512a0d58",
   "metadata": {},
   "source": [
    "Q10. You are comparing the performance of two regularized linear models using different types of\n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B\n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the\n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization\n",
    "method?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92132f22-72b0-418d-a962-eff7a57d973f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
