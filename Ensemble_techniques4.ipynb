{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3b9de06-96a0-44ad-9721-3f4bc58dc692",
   "metadata": {},
   "source": [
    "Q1. You are working on a machine learning project where you have a dataset containing numer#cal and\n",
    "categorical features. You have identified that some of the features are highly correlated and there are\n",
    "missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "\n",
    "Design a pipeline that includes the following steps\"\n",
    "- Use an automated feature selection method to identify the important features in the dataset.\n",
    "- Create a numerical p#pel#ne that includes the following steps\"\n",
    "- Impute the missing values in the numerical columns using the mean of the column values.\n",
    "- Scale the numerical columns us#ng standardisation.\n",
    "- Create a categorical pipeline that includes the following steps\"\n",
    "- Impute the missing values in the categorical columns using the most frequent value of the column.\n",
    "- One-hot encode the categorical columns.\n",
    "- Combine the numerical and categorical pipelines us#ng a ColumnTransformer.\n",
    "- Use a Random Forest Classifier to build the final model.\n",
    "- Evaluate the accuracy of the model on the test dataset.\n",
    "Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretat#on of the results and suggest possible #mprovements forthe pipeline."
   ]
  },
  {
   "cell_type": "raw",
   "id": "13ab928c-2928-41bd-8e7e-2638fb04e16a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import seaborn as sns\n",
    "# # Load dataset (example)\n",
    "# df = sns.load_dataset('iris')\n",
    "# X = df.drop('', axis=1)\n",
    "# y = df['target']\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Numerical pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Feature selection\n",
    "feature_selection = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# Final pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Interpretation: The model accuracy provides insight into how well the pipeline handles the data.\n",
    "# Possible Improvements: Experiment with different feature selection methods, classifiers, and hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c56265-3bdf-4c75-ac45-54fa5f53d388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1bec1fa-add2-4b30-ba5b-6a036445f646",
   "metadata": {},
   "source": [
    "Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
    "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate #ts\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc0e83-a14d-4825-9e51-96b2acc39a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f080ab2-fc5e-4004-a540-c879e3ce4d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2c53d-a9f9-4a8a-9af9-f566bd8e60c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315cca2-a6ac-472e-815a-8108e7c4ef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dd31f-b6e7-4b6d-9d5a-0edd741dac81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987758ad-a226-4881-b1e1-16357ae1a026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6bcfe-c50c-4f50-9482-8924b3a97939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed954f1-c10e-44ef-b738-d81965ccb9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0f76c-e781-4309-9047-545da3d11d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a714e-91e0-4d62-a514-2531740c022e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33db15f-555b-48da-95bc-3ea1a9cf3c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10489c2-d4a0-4cb0-a126-8c8218ac63bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
