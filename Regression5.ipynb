{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e537a6d-90db-48f0-87bb-cd4072ad24d4",
   "metadata": {},
   "source": [
    "Q1. What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1d9a9-ee25-45d4-b97d-e01e8522b663",
   "metadata": {},
   "source": [
    "Elastic Net Regression: Elastic Net combines both L1 (Lasso) and L2 (Ridge) regularization penalties. It aims to address limitations of both techniques by balancing their properties.\n",
    "\n",
    "Differences:\n",
    "\n",
    "- Ordinary Least Squares (OLS): No regularization.\n",
    "- Ridge Regression: L2 penalty (sum of squared coefficients).\n",
    "- Lasso Regression: L1 penalty (sum of absolute values of coefficients).\n",
    "- Elastic Net Regression: A combination of L1 and L2 penalties, controlled by two parameters (alpha and l1_ratio)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7b8b71e-b34a-4607-86b3-fe8ef2957ffa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0308448-31ca-49e2-97c4-78d2950793be",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee58a3e-d5d1-4b2e-be22-9d6e5abb5755",
   "metadata": {},
   "source": [
    "Cross-Validation: Optimal values of alpha (overall regularization strength) and l1_ratio (balance between L1 and L2) are chosen through cross-validation. Grid search or randomized search techniques are commonly used to evaluate different combinations and select the best performing set."
   ]
  },
  {
   "cell_type": "raw",
   "id": "65e834b7-2a7e-4742-af49-6290031535ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6880b338-55a0-452c-85d4-2d4bf14bfa65",
   "metadata": {},
   "source": [
    "Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787277cb-cec0-4d96-8c54-2c7281522ce4",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "\n",
    "- Feature Selection: Like Lasso, it can perform feature selection by shrinking some coefficients to zero.\n",
    "- Multicollinearity Handling: Like Ridge, it handles multicollinearity well.\n",
    "- Flexibility: Combines the strengths of both Lasso and Ridge.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "- Complexity: Involves tuning two hyperparameters (alpha and l1_ratio), which can be more complex and computationally intensive.\n",
    "- Bias: May introduce bias due to regularization."
   ]
  },
  {
   "cell_type": "raw",
   "id": "19694382-d3a2-4126-8bbf-e916e62353ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c60cc2-9e42-4ba2-bd7a-beee63035a5e",
   "metadata": {},
   "source": [
    "Q4. What are some common use cases for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00520d-c54c-4efb-a71e-cee6590faa98",
   "metadata": {},
   "source": [
    "Use Cases:\n",
    "\n",
    "- High-Dimensional Data: Useful when the number of predictors is much larger than the number of observations.\n",
    "- Multicollinearity: Effective in datasets where predictors are highly correlated.\n",
    "- Feature Selection: Suitable for scenarios where automatic feature selection is desired alongside predictive modeling."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c7420fe-dcb0-43c1-877a-80f0b28afbe1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07a723c2-2abe-48af-b130-91e5859db98e",
   "metadata": {},
   "source": [
    "Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5f77b-b686-4409-9d4c-2b65a698ab5e",
   "metadata": {},
   "source": [
    "Magnitude, Direction, and Selection: Coefficients indicate the direction (positive or negative) and magnitude of the relationship between predictors and the response variable. Coefficients shrunk to zero indicate non-important features. Due to combined penalties, coefficients reflect a balance between Lasso and Ridge effects."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e6df93fe-f817-4f35-8398-a6b9bfeee3fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4056c4a3-7cf7-4bfa-b3b0-805bf1670ff6",
   "metadata": {},
   "source": [
    "Q6. How do you handle missing values when using Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3641407-2dde-4568-80da-38fe5d901fcb",
   "metadata": {},
   "source": [
    "Handling Missing Values:\n",
    "\n",
    "- Imputation: Common techniques include mean, median, mode imputation, or more advanced methods like k-nearest neighbors (KNN) imputation.\n",
    "- Removing: In some cases, removing rows or columns with missing values might be appropriate."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a83b24b0-3e0a-49bd-aad2-5716cca8f20a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6334558a-6598-430e-8b1e-13ba43d9eb6b",
   "metadata": {},
   "source": [
    "Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ed7ae-ba43-4951-9d27-086c2382a617",
   "metadata": {},
   "source": [
    "Feature Selection:\n",
    "\n",
    "- Fit the Model: Train the Elastic Net model on your dataset.\n",
    "- Identify Non-Zero Coefficients: Features with non-zero coefficients are considered important.\n",
    "- Subset Selection: Select a subset of features with non-zero coefficients for further analysis or modeling."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2d9a239-3767-492b-92ee-00d737f23148",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1236690a-19a4-412c-b3cb-8ccb6d2fe7ac",
   "metadata": {},
   "source": [
    "Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f275e3-87a1-4095-b27a-ec407d67e15a",
   "metadata": {},
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Train your ElasticNet model\n",
    "model = ElasticNet().fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "with open('elastic_net_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Load the model from the file\n",
    "with open('elastic_net_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09af5da0-17e2-437f-9ed7-4624654175ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34951879-5efe-4b62-b298-e3b58710cdbf",
   "metadata": {},
   "source": [
    "Q9. What is the purpose of pickling a model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c54d06-693b-4562-9cd1-4036bff8c7b8",
   "metadata": {},
   "source": [
    "Purpose of Pickling:\n",
    "\n",
    "- Model Persistence: Save a trained model to disk for later use without needing to retrain.\n",
    "- Deployment: Facilitate model deployment in production environments.\n",
    "- Sharing: Share the model with others, ensuring reproducibility of results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5a09841-f531-473a-9dda-4e92c0584279",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
