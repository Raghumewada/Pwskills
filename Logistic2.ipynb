{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98230e36-53e0-4b3e-8edd-1af3cf912db1",
   "metadata": {},
   "source": [
    "Q1. Purpose of Grid Search CV in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d874aa-0f58-4894-a7f1-4f05005a06b5",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "\n",
    "- To systematically find the best hyperparameters for a machine learning model by evaluating a grid of parameter combinations.\n",
    "\n",
    "How It Works:\n",
    "\n",
    "- Defines a grid of hyperparameter values.\n",
    "- Performs cross-validation for each combination.\n",
    "- Selects the combination with the best performance metric."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e49869e3-4b40-4442-a98a-aa139975a4b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71beb54f-555b-404c-8999-ec6874d165d1",
   "metadata": {},
   "source": [
    "Q2. Difference Between Grid Search CV and Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37b2ea-001b-430b-8225-a904711bb231",
   "metadata": {},
   "source": [
    "Grid Search CV:\n",
    "\n",
    "- Exhaustively searches all possible combinations in a specified grid.\n",
    "- Use When: You have a smaller parameter space and can afford the computational cost.\n",
    "\n",
    "Randomized Search CV:\n",
    "\n",
    "- Randomly samples a fixed number of combinations from the parameter space.\n",
    "- Use When: You have a large parameter space and need a more efficient search."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c532bea-8b98-4304-a0b5-c5f0f6ad7bcc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76d4408-2e14-4698-9cca-7f54e30aec0a",
   "metadata": {},
   "source": [
    "Q3. Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c992b-8597-449c-8bc5-40379ff5ce94",
   "metadata": {},
   "source": [
    "Definition:\n",
    "\n",
    "- Occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance estimates.\n",
    "\n",
    "Problem:\n",
    "\n",
    "- It results in models that do not generalize well to new data.\n",
    "\n",
    "Example:\n",
    "\n",
    "- Using future information in time series forecasting."
   ]
  },
  {
   "cell_type": "raw",
   "id": "542bcc1d-f154-4e5c-a809-97b07c114088",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0490911-7215-462e-8c99-6d0fd3a4dae2",
   "metadata": {},
   "source": [
    "Q4. Preventing Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a154c8-c954-4a17-812a-c7371a9cbae4",
   "metadata": {},
   "source": [
    "Strategies:\n",
    "\n",
    "- Properly Split Data: Ensure training, validation, and test sets are correctly separated.\n",
    "- Pipeline Usage: Apply data transformations within cross-validation to avoid leaking information from the test set into the training process.\n",
    "- Feature Selection: Perform feature selection on training data only."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5b81afb-a851-4a15-a9fa-da659fe20840",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02d75ed4-cfff-4fe2-9a63-76b680fee432",
   "metadata": {},
   "source": [
    "Q5. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cced50b-252e-4511-b6c8-2bbb55eca8c9",
   "metadata": {},
   "source": [
    "Definition:\n",
    "\n",
    "- A table used to evaluate the performance of a classification model, showing the actual vs. predicted classifications.\n",
    "\n",
    "Components:\n",
    "\n",
    "- True Positives (TP): Correctly predicted positives.\n",
    "- True Negatives (TN): Correctly predicted negatives.\n",
    "- False Positives (FP): Incorrectly predicted positives.\n",
    "- False Negatives (FN): Incorrectly predicted negatives."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e72759f-5ff3-444e-ab93-8e46085f3c0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e94337e-63c2-4ec3-9db5-9f27543d3dbe",
   "metadata": {},
   "source": [
    "Q6. Precision vs. Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4dc4e-7466-4939-90a6-6d5d8472d90d",
   "metadata": {},
   "source": [
    "Precision:\n",
    "\n",
    "- Definition: The ratio of correctly predicted positive observations to the total predicted positives.\n",
    "- Formula: Precision= TP/(TP+FP)\n",
    "\n",
    "Recall:\n",
    "\n",
    "- Definition: The ratio of correctly predicted positive observations to all actual positives.\n",
    "- Formula: Recall=TP/(TP+FN)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a7ce833-6b8f-4892-af3c-80bd17e6f159",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "607069ae-3a84-4419-9126-4f259fe5e901",
   "metadata": {},
   "source": [
    "Q7. Interpreting a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19cf0d-f700-4058-9f85-5ab997ad5fa6",
   "metadata": {},
   "source": [
    "Identifying Errors:\n",
    "\n",
    "- False Positives (FP): Indicates instances incorrectly classified as positive.\n",
    "- False Negatives (FN): Indicates instances incorrectly classified as negative."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5783ca89-2e1c-4603-a4e0-744434e8a48a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709e5b10-4211-4df7-adc3-1b77dc548661",
   "metadata": {},
   "source": [
    "Q8. Common Metrics Derived from a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8cc2f-3f72-4245-bd0d-5018f1ebd3d6",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "\n",
    "Accuracy: TP+TN/(TP+TN+FP+FN)\n",
    "Precision: TP/(TP+FP)\n",
    "Recall (Sensitivity):TP/( TP+FN)\n",
    "F1 Score:2( PrecisionÃ—Recall/Precision+Recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e5be8d9-b13c-46e1-91a4-2fb4ed51af97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "113b0b6e-0007-43da-9ba1-59ad0887a76f",
   "metadata": {},
   "source": [
    "Q9. Relationship Between Accuracy and Confusion Matrix Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b158b08-8b34-429e-80f4-8ad70db31e76",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "- Represents the proportion of correctly classified instances out of the total instances.\n",
    "- Formula:TP+TN/ Total\n",
    "- Relation: High accuracy might still mask poor performance on imbalanced datasets."
   ]
  },
  {
   "cell_type": "raw",
   "id": "435ec92f-8afb-4c2b-91bf-b5c96ba9596f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3acc14eb-6418-42cf-bfe5-caa783ef2f60",
   "metadata": {},
   "source": [
    "Q10. Using a Confusion Matrix to Identify Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d3bc7-1622-4e04-a2eb-43f1827d694e",
   "metadata": {},
   "source": [
    "Identifying Biases:\n",
    "\n",
    "- Class Imbalance: High number of FNs or FPs might indicate bias towards a particular class.\n",
    "- Error Analysis: Examine the distribution of FPs and FNs to understand if the model is systematically making specific errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5cfb4-b8eb-48eb-9c31-2dda07f0f4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
