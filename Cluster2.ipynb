{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37a6fd7-7d5e-44d3-a346-e1384906de0e",
   "metadata": {},
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60925126-2d4d-4af3-9698-9d9d0d16f741",
   "metadata": {},
   "source": [
    "- Definition: A method of clustering that builds a hierarchy of clusters by either merging smaller clusters (agglomerative) or splitting larger clusters (divisive).\n",
    "- Difference from Other Techniques: Unlike partitioning methods (e.g., K-means), hierarchical clustering does not require specifying the number of clusters in advance and produces a tree-like structure called a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a4576-1912-456b-a8e0-1915c9f4e115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94570c23-8b7b-4c7e-b3a4-955f4101411b",
   "metadata": {},
   "source": [
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207dde41-c1ae-419e-b5d1-5ee3468ba4d2",
   "metadata": {},
   "source": [
    "Agglomerative (Bottom-Up):\n",
    "\n",
    "- Starts with each data point as its own cluster.\n",
    "- Iteratively merges the closest pairs of clusters until all points are in one cluster.\n",
    "\n",
    "Divisive (Top-Down):\n",
    "\n",
    "- Starts with all data points in one cluster.\n",
    "- Recursively splits clusters into smaller clusters until each point is in its own cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5ac17-4ab5-4886-bcca-b3ab9ef66ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b050c62-5e82-401c-b5cb-6ae99c34df57",
   "metadata": {},
   "source": [
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c14514-72a3-4678-91b7-1a5476d21d6a",
   "metadata": {},
   "source": [
    "Methods:\n",
    "- Single Linkage: Minimum distance between points in two clusters.\n",
    "- Complete Linkage: Maximum distance between points in two clusters.\n",
    "- Average Linkage: Average distance between points in two clusters.\n",
    "- Centroid Linkage: Distance between the centroids of two clusters.\n",
    "- Wardâ€™s Method: Increase in variance when clusters are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b205f-c243-4893-8a7f-ba1bdb472cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1ba8be-1383-4059-af61-363b3fc8434a",
   "metadata": {},
   "source": [
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf883b-1e6a-4a0c-9908-7eec3b7a17de",
   "metadata": {},
   "source": [
    "Methods:\n",
    "- Dendrogram Analysis: Cutting the dendrogram at a particular height.\n",
    "- Elbow Method: Plotting the distance metrics and looking for an \"elbow.\"\n",
    "- Silhouette Score: Evaluating how similar each point is to its own cluster compared to other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf790f2f-c9a0-4046-8866-ceb7084b8841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "142837cb-8417-4104-a44b-3c308237b906",
   "metadata": {},
   "source": [
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfac68-8cba-4eca-a6d2-ae69326b5d17",
   "metadata": {},
   "source": [
    "- Definition: A tree-like diagram that records the sequences of merges or splits.\n",
    "- Usefulness: Visualizes the arrangement of clusters and helps in determining the number of clusters by cutting the dendrogram at different heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa5df74-091f-4ae5-a84b-9639092ffd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc268202-9b60-4f36-9f9e-ae4cc0d9b3a4",
   "metadata": {},
   "source": [
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4d3af-4557-4b90-8335-5bc7ebe11282",
   "metadata": {},
   "source": [
    "- Numerical Data: Common distance metrics include Euclidean, Manhattan, and Minkowski distances.\n",
    "- Categorical Data: Use metrics like Hamming distance or Gower distance, which handle categorical variables appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b71f0c-1125-4978-959c-ab6ac84d0bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5edc70-7c92-4cbe-99b9-e1c680fe8a6d",
   "metadata": {},
   "source": [
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953f1d0-57a8-418e-ae4e-4152e034808e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
